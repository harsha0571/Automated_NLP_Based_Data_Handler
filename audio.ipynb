{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./datasets/audio/this-is-the-third-crime-of-violence-to-occur-in-that-vicinity-within-the-past-month.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='test.wav'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "# AudioSegment.converter = \"C:\\Path_Programs\"\n",
    "\n",
    "# install ffmpeg and add to path\n",
    "# install with pip -> pydub , pyaudio and restart vs code before running \n",
    "\n",
    "# print(os.getcwd())\n",
    "\n",
    "# files                                                                         \n",
    "src = \"testing.mp3\"\n",
    "dst = \"test.wav\"\n",
    "# os.chmod(src, 777)\n",
    "\n",
    "# convert wav to mp3                                                            \n",
    "sound = AudioSegment.from_mp3(src)\n",
    "sound.export(dst, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "police here now what's the problem of kids\n"
     ]
    }
   ],
   "source": [
    "# initialize the recognizer\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# open the file\n",
    "with sr.AudioFile(\"test.wav\") as source:\n",
    "    # listen for the data (load audio to memory)\n",
    "    #r.adjust_for_ambient_noise(source,duration=0.5)\n",
    "    \n",
    "    audio_data = r.record(source)\n",
    "    # recognize (convert from speech to text)\n",
    "    text = r.recognize_google(audio_data)\n",
    "    print(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import wave\n",
    "import json \n",
    "\n",
    "def get_text_from_voice(filename):\n",
    "\n",
    "    # if not os.path.exists(\"model\"):\n",
    "    #     print (\"Please download the model from https://alphacephei.com/vosk/models and unpack as 'model' in the current folder.\")\n",
    "    #     exit (1)\n",
    "\n",
    "    wf = wave.open(filename, \"rb\")\n",
    "    if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
    "        print (\"Audio file must be WAV format mono PCM.\")\n",
    "        exit (1)\n",
    "    #model = Model(\"datasets\\\\vosk-model-small-en-us-0.15\")\n",
    "    model = Model(\"datasets\\\\vosk-model-en-us-0.22\")\n",
    "    rec = KaldiRecognizer(model, wf.getframerate())\n",
    "    rec.SetWords(True)\n",
    "\n",
    "    text_lst =[]\n",
    "    p_text_lst = []\n",
    "    p_str = []\n",
    "    len_p_str = []\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if rec.AcceptWaveform(data):\n",
    "            text_lst.append(rec.Result())\n",
    "            print(rec.Result())\n",
    "        else:\n",
    "            p_text_lst.append(rec.PartialResult())\n",
    "            print(rec.PartialResult())\n",
    "\n",
    "    if len(text_lst) !=0:\n",
    "        jd = json.loads(text_lst[0])\n",
    "        txt_str = jd[\"text\"]\n",
    "        \n",
    "    elif len(p_text_lst) !=0: \n",
    "        for i in range(0,len(p_text_lst)):\n",
    "            temp_txt_dict = json.loads(p_text_lst[i])\n",
    "            p_str.append(temp_txt_dict['partial'])\n",
    "        \n",
    "        len_p_str = [len(p_str[j]) for j in range(0,len(p_str))]\n",
    "        max_val = max(len_p_str)\n",
    "        indx = len_p_str.index(max_val)\n",
    "        txt_str = p_str[indx]\n",
    "            \n",
    "    else:\n",
    "        txt_str =''\n",
    "\n",
    "    return txt_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vosk import Model, KaldiRecognizer\n",
    "import pyaudio\n",
    "\n",
    "#model = Model(\"datasets\\\\vosk-model-small-en-us-0.15\")\n",
    "model = Model(\"datasets\\\\vosk-model-en-us-0.22\")\n",
    "recognizer = KaldiRecognizer(model, 16000)\n",
    "\n",
    "mic = pyaudio.PyAudio()\n",
    "stream = mic.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=8192)\n",
    "stream.start_stream()\n",
    "\n",
    "def Listen():\n",
    "    print(\"\")\n",
    "    print(\"Listening...\")\n",
    "    print(\"\")\n",
    "\n",
    "    while True:\n",
    "\n",
    "        data = stream.read(40960)\n",
    "\n",
    "        if recognizer.AcceptWaveform(data):\n",
    "            text = recognizer.Result()\n",
    "            p = text[14:-3]\n",
    "            print(f\"You Said : {p}\")\n",
    "\n",
    "            if len(p)>0:\n",
    "                return p\n",
    "            \n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio file must be WAV format mono PCM.\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"not sure\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"no show\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"no show\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"not sure\"\n",
      "}\n",
      "{\"text\": \"\"}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"pat her\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"pat her move\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"pat her move\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"pat her move\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"pat her move around in\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"pat her move around and\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"pat her move around and\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"pat her move around instead\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"image\"\n",
      "}\n",
      "{\"text\": \"\"}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"in\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"brute\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"brute\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"brute\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"brute\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"the group of students\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"the group of students\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"the brink of civil\"\n",
      "}\n",
      "{\"text\": \"\"}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"we want to\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"two\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"two\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"two\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"i'm going to crash tomorrow\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"we were proposed law\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"we were proposed law\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"we were proposed law\"\n",
      "}\n",
      "{\"text\": \"\"}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"partial\" : \"\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'show bomb'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text_from_voice(\"./datasets/audio/third_crime_in_soho.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Listening...\n",
      "\n",
      "You Said : what's this rate\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"what's this rate\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Listen()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "daca86dfe90386ebecafa86302dd102978461e1263ffd5af8c9f541b523ba9f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
