{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mapping docid docloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def append_data(json_data,dataset):\n",
    "\n",
    "    len_dset = len(dataset)\n",
    "\n",
    "    for i,val in enumerate(json_data):\n",
    "        data = np.array([(len_dset + i , val['doc_loc'])], dtype=[('doc_id', 'int32'), ('doc_loc', 'S10')])\n",
    "        dataset.resize(dataset.shape[0]+1, axis=0)   \n",
    "        dataset[len_dset + i] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_json_data 2\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open('generated.json', 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "len_json_data = len(json_data)\n",
    "print(\"len_json_data\",len_json_data)\n",
    "\n",
    "file = h5py.File('doc_info1.hdf5', 'a')\n",
    "\n",
    "if 'my_dataset' not in file:\n",
    "    dataset = file.create_dataset('my_dataset', shape=(0,), dtype=[('doc_id', 'int32'), ('doc_loc', 'S10')],maxshape=(None,))\n",
    "else:\n",
    "    dataset = file['my_dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len dset:  2\n",
      "0 (0, b'640c08980f')\n",
      "1 (1, b'640c0898a3')\n"
     ]
    }
   ],
   "source": [
    "append_data(json_data,dataset)\n",
    "\n",
    "print(\"len dset: \",len(dataset))\n",
    "\n",
    "for i,val in enumerate(dataset):\n",
    "    print(i,val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generating keywords file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, b'640c08980f') (1, b'640c0898a3')]\n",
      "{0: '640c08980f', 1: '640c0898a3'}\n"
     ]
    }
   ],
   "source": [
    "import vaex\n",
    "import json \n",
    "import h5py\n",
    "\n",
    "# df = vaex.open('doc_info1.hdf5')\n",
    "df = h5py.File('doc_info1.hdf5', 'a')\n",
    "# for i,val in enumerate(df.items()):\n",
    "#     print(i,val)\n",
    "\n",
    "dataset = df['my_dataset']\n",
    "data = dataset[:]\n",
    "\n",
    "print((data))\n",
    "# print((data)[0])\n",
    "doc_map = {}\n",
    "# print(len(data))\n",
    "for i in range(len(data)):\n",
    "    # print(data)\n",
    "    doc_id = data[i][0]\n",
    "    doc_location = data[i][1].decode('UTF-8')\n",
    "    \n",
    "    doc_map[doc_id] = doc_location\n",
    "\n",
    "# for doc_id, doc_location in doc_map.items():\n",
    "#     print(doc_id,doc_location)\n",
    "print(doc_map)\n",
    "with open('generated.json', 'r') as f:\n",
    "    data_json = json.load(f)\n",
    "\n",
    "# # print(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keyword_obj in data_json:\n",
    "    key_arr = keyword_obj['keywords_array']\n",
    "    \n",
    "    for keyarr_obj in range(len(key_arr)):\n",
    "\n",
    "        key_obj = key_arr[keyarr_obj]\n",
    "        # print(key_obj)\n",
    "        keyword_name = key_obj['keyword']\n",
    "        keyword_score = key_obj['score']\n",
    "        \n",
    "        # print(keyword_name,keyword_score)\n",
    "\n",
    "        file2 = h5py.File(keyword_name + \"Index.hdf5\", 'a')\n",
    "        file3 = h5py.File(keyword_name + \"Bias.hdf5\", 'a')\n",
    "        \n",
    "        if keyword_name not in file2:\n",
    "            dataset2 = file2.create_dataset(keyword_name, shape=(0,), maxshape=(None,), dtype = [('id', int), ('score', float)])\n",
    "        else:\n",
    "            dataset2 = file2[keyword_name]\n",
    "        \n",
    "        if keyword_name not in file3:\n",
    "            dataset3 = file3.create_dataset(keyword_name, shape=(0,), maxshape=(None,), dtype = [('id', int),('bias', int)])\n",
    "        else:\n",
    "            dataset3 = file3[keyword_name]\n",
    "\n",
    "        for doc_id, doc_location in doc_map.items():\n",
    "\n",
    "            if doc_location in keyword_obj['doc_loc']:\n",
    "                \n",
    "                dataset2.resize((dataset2.shape[0] + 1,))\n",
    "                dataset3.resize((dataset3.shape[0] + 1,))\n",
    "                # print(doc_location,keyword_score)\n",
    "                # print(type(int(doc_location)),type(keyword_score))\n",
    "                dataset2[-1] = (doc_id, keyword_score)\n",
    "                dataset3[-1:] = (doc_id, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                            </th><th>Kimberly  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i></td><td>(1, 1)    </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "  #  Kimberly\n",
       "  0  (1, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import vaex\n",
    "df98 = vaex.open('KimberlyBias.hdf5')\n",
    "df98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                            </th><th>Jody   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i></td><td>(0, 0.)</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "  #  Jody\n",
       "  0  (0, 0.)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import vaex\n",
    "df97 = vaex.open('JodyIndex.hdf5')\n",
    "df97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import vaex \n",
    "# dic= {'id':[2,56,78,546],'score':[0.497,0.123,0.99,0.67]}\n",
    "# df4= vaex.from_dict(dic)\n",
    "# name='AA'\n",
    "# df4.export(name + \".hdf5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
