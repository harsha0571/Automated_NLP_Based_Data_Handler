{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparision of python modules for keyword extraction\n",
    "### spaCy\n",
    "Setup steps:  \n",
    "* pip install -U spacy  \n",
    "* python -m spacy download en_core_web_lg\n",
    "* python -m spacy validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Python, Cython, MIT, Matthew Honnibal, Ines Montani, Explosion)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "text = \"\"\"spaCy is an open-source software library for advanced natural language processing, \n",
    "written in the programming languages Python and Cython. The library is published under the MIT license\n",
    "and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\"\"\"\n",
    "doc = nlp(text)\n",
    "print(doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'linear', 'corresponding', 'numbers', 'sets', 'equations', 'considered', 'types', 'components', 'constraints', 'set', 'bounds', 'systems', 'algorithms', 'solving', 'compatibility', 'constructing', 'supporting', 'nonstrict', 'inequations', 'given', 'minimal', 'upper', 'mixed', 'solutions', 'construction', 'generating', 'criteria', 'natural', 'system', 'diophantine', 'strict'}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "text = \"\"\"Compatibility of systems of linear constraints over the set of natural numbers.\n",
    "Criteria of compatibility of a system of linear Diophantine equations, strict inequations,\n",
    "and nonstrict inequations are considered. Upper bounds for components of a minimal set of\n",
    "solutions and algorithms of construction of minimal generating sets of solutions for all types\n",
    "of systems are given. These criteria and the corresponding algorithms for constructing a minimal\n",
    "supporting set of solutions can be used in solving all the considered types systems and systems of mixed types.\"\"\"\n",
    "\n",
    "# load a spaCy model, depending on language, scale, etc.\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "\n",
    "def get_hotwords(text):\n",
    "    result = []\n",
    "    pos_tag = ['PROPN', 'ADJ', 'NOUN','VERB'] \n",
    "    doc = nlp(text.lower()) \n",
    "    for token in doc:\n",
    "        # 3\n",
    "        if(token.text in nlp.Defaults.stop_words or token.text in punctuation):\n",
    "            continue\n",
    "        # 4\n",
    "        if(token.pos_ in pos_tag):\n",
    "            result.append(token.text)\n",
    "                \n",
    "    return result \n",
    "\n",
    "output = get_hotwords(text)\n",
    "print(set(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YAKE\n",
    "Yet Another Keyword Extractor (Yake) library selects the most important keywords using the text statistical features method from the article. With the help of YAKE, you can control the extracted keyword word count and other features.\n",
    "\n",
    "* pip install yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for the string:  spaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython. The library is published under the MIT license and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\n",
      "('Cython', 0.053691021027863564)\n",
      "('Python', 0.06651575167590484)\n",
      "('spaCy', 0.10241338875304772)\n",
      "('processing', 0.10241338875304772)\n",
      "('written', 0.10241338875304772)\n",
      "('software', 0.11761141438285434)\n",
      "('library', 0.11761141438285434)\n",
      "('open-source', 0.13442462743719766)\n",
      "('advanced', 0.13442462743719766)\n",
      "('natural', 0.13442462743719766)\n",
      "('programming', 0.13442462743719766)\n",
      "('language', 0.13986690653033845)\n",
      "('languages', 0.13986690653033845)\n",
      "('Montani', 0.1646146628535413)\n",
      "('Explosion', 0.1646146628535413)\n",
      "('MIT', 0.19838041526103037)\n",
      "('Matthew', 0.19838041526103037)\n",
      "('Honnibal', 0.19838041526103037)\n",
      "('Ines', 0.19838041526103037)\n",
      "('published', 0.35038366644254865)\n",
      "('license', 0.35038366644254865)\n",
      "('main', 0.35038366644254865)\n",
      "('developers', 0.35038366644254865)\n",
      "('founders', 0.35038366644254865)\n",
      "('company', 0.35038366644254865)\n",
      "for the string:  wow that brightest star do you remember the pan pacific bank robbery where four people were killed and the subsequent arrest of the perp where a young man was shot and killed\n",
      "('killed', 0.08407519304970143)\n",
      "('wow', 0.08646269674286734)\n",
      "('brightest', 0.12883217637511718)\n",
      "('star', 0.12883217637511718)\n",
      "('remember', 0.12883217637511718)\n",
      "('pan', 0.12883217637511718)\n",
      "('pacific', 0.12883217637511718)\n",
      "('bank', 0.12883217637511718)\n",
      "('robbery', 0.12883217637511718)\n",
      "('people', 0.12883217637511718)\n",
      "('subsequent', 0.12883217637511718)\n",
      "('arrest', 0.12883217637511718)\n",
      "('perp', 0.12883217637511718)\n",
      "('young', 0.12883217637511718)\n",
      "('man', 0.12883217637511718)\n",
      "('shot', 0.12883217637511718)\n",
      "for the string:  THE ANDNRENT AND UNACCEPTABLE TRUTH OF\n",
      "                    CUSTODIAL DEATH\n",
      "('ANDNRENT', 0.15831692877998726)\n",
      "('UNACCEPTABLE', 0.15831692877998726)\n",
      "('TRUTH', 0.15831692877998726)\n",
      "('CUSTODIAL', 0.2718250226855089)\n",
      "('DEATH', 0.2718250226855089)\n"
     ]
    }
   ],
   "source": [
    "import yake\n",
    "kw_extractor = yake.KeywordExtractor()\n",
    "text = \"\"\"spaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython. The library is published under the MIT license and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\"\"\"\n",
    "textFromAudio = \"wow that brightest star do you remember the pan pacific bank robbery where four people were killed and the subsequent arrest of the perp where a young man was shot and killed\"\n",
    "textFromImages = \"\"\"THE ANDNRENT AND UNACCEPTABLE TRUTH OF\n",
    "                    CUSTODIAL DEATH\"\"\"\n",
    "\n",
    "\n",
    "def TestYake(doc):\n",
    "    language = \"en\"\n",
    "    max_ngram_size = 1 # increase to get phrases instead of words\n",
    "    deduplication_threshold = 0.9\n",
    "    numOfKeywords = int(0.45 * len(doc)) # controls no of keywords to extract \n",
    "    custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, top=numOfKeywords, features=None)\n",
    "    keywords = custom_kw_extractor.extract_keywords(doc)\n",
    "    print(\"for the string: \",doc)\n",
    "    for kw in keywords:\n",
    "        print(kw)\n",
    "\n",
    "TestYake(text)\n",
    "TestYake(textFromAudio)\n",
    "TestYake(textFromImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAKE\n",
    "\n",
    "You can form a powerful keyword extraction method by combining the Rapid Automatic Keyword Extraction (RAKE) algorithm with the NLTK toolkit. It is known as rake-nltk.\n",
    "\n",
    "* pip install rake-nltk\n",
    "* import nltk\n",
    "* nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0, 'written'), (1.0, 'spacy'), (1.0, 'published'), (1.0, 'open'), (1.0, 'library'), (1.0, 'founders'), (1.0, 'cython')]\n"
     ]
    }
   ],
   "source": [
    "from rake_nltk import Rake\n",
    "\n",
    "\n",
    "r = Rake(min_length=1, max_length=1) \n",
    "text = \"\"\"spaCy is an open-source software library for advanced natural language processing,\n",
    "written in the programming languages Python and Cython. The library is published under the MIT license\n",
    "and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\"\"\"\n",
    "r.extract_keywords_from_text(text)\n",
    "keyword_extracted = r.get_ranked_phrases_with_scores()\n",
    "print(keyword_extracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim\n",
    "Gensim is primarily developed for topic modeling. Over time, Gensim added other NLP tasks such as summarization, finding text similarity, etc. Here we will demonstrate the use of Genism for keyword extraction tasks.\n",
    "* pip3 install gensim==3.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('factor', 0.3066938262406011),\n",
       " ('convergence', 0.3065532260323327),\n",
       " ('rescaling', 0.24358369124679524),\n",
       " ('multiplicative', 0.23877639442201123),\n",
       " ('function', 0.23315315782740828),\n",
       " ('kullback', 0.20739874793094204),\n",
       " ('gradient', 0.17745105527488267),\n",
       " ('algorithm', 0.1688639034957118),\n",
       " ('matrix', 0.16540489544978382),\n",
       " ('rules', 0.1597530896224829),\n",
       " ('update', 0.15975308962248286),\n",
       " ('squares error', 0.1597530896224828),\n",
       " ('optimally', 0.15975308962248275)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for short text\n",
    "\n",
    "import gensim\n",
    "text = \"Non-negative matrix factorization (NMF) has previously been shown to \" + \\\n",
    "\"be a useful decomposition for multivariate data. Two different multiplicative \" + \\\n",
    "\"algorithms for NMF are analyzed. They differ only slightly in the \" + \\\n",
    "\"multiplicative factor used in the update rules. One algorithm can be shown to \" + \\\n",
    "\"minimize the conventional least squares error while the other minimizes the  \" + \\\n",
    "\"generalized Kullback-Leibler divergence. The monotonic convergence of both  \" + \\\n",
    "\"algorithms can be proven using an auxiliary function analogous to that used \" + \\\n",
    "\"for proving convergence of the Expectation-Maximization algorithm. The algorithms  \" + \\\n",
    "\"can also be interpreted as diagonally rescaled gradient descent, where the  \" + \\\n",
    "\"rescaling factor is optimally chosen to ensure convergence.\"\n",
    "gensim.summarization.keywords(text, \n",
    "        ratio=0.5,               # use 50% of original text\n",
    "        words=None,              # Number of returned words\n",
    "        split=True,              # Whether split keywords\n",
    "        scores=True,            # Whether score of keyword\n",
    "        pos_filter=('NN', 'JJ'), # Part of speech (nouns, adjectives etc.) filters\n",
    "        lemmatize=True,         # If True - lemmatize words\n",
    "        deacc=True)              # If True - remove accentuation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('factor', 0.3066938262406005), ('convergence', 0.30655322603233226), ('rescaling', 0.24358369124679452), ('multiplicative', 0.23877639442201173), ('function', 0.23315315782740748), ('kullback', 0.20739874793094265), ('gradient', 0.17745105527488209)]\n"
     ]
    }
   ],
   "source": [
    "# for large text\n",
    "\n",
    "def get_keywords_gensim(docs):\n",
    "    \n",
    "    keywords=gensim.summarization.keywords(docs, \n",
    "                                ratio=None, \n",
    "                                words=10,         \n",
    "                                split=True,             \n",
    "                                scores=True,           \n",
    "                                pos_filter=None, \n",
    "                                lemmatize=True,         \n",
    "                                deacc=True)              \n",
    "    \n",
    "    return keywords\n",
    "\n",
    "keywords=get_keywords_gensim(text)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KeyBERT\n",
    "KeyBERT is a minimal and easy-to-use keyword extraction technique that leverages BERT embeddings to create keywords and keyphrases that are most similar to a document.\n",
    "* pip install keybert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For string:  Supervised learning is the machine learning task of learning a function that\n",
      "        maps an input to an output based on example input-output pairs. It infers a\n",
      "        function from labeled training data consisting of a set of training examples.\n",
      "        In supervised learning, each example is a pair consisting of an input object\n",
      "        (typically a vector) and a desired output value (also called the supervisory signal). \n",
      "        A supervised learning algorithm analyzes the training data and produces an inferred function, \n",
      "        which can be used for mapping new examples. An optimal scenario will allow for the \n",
      "        algorithm to correctly determine the class labels for unseen instances. This requires \n",
      "        the learning algorithm to generalize from the training data to unseen situations in a \n",
      "        'reasonable' way (see inductive bias).\n",
      "[('supervised', 0.6676),\n",
      " ('labeled', 0.4896),\n",
      " ('learning', 0.4813),\n",
      " ('training', 0.4134),\n",
      " ('labels', 0.3947),\n",
      " ('supervisory', 0.3297),\n",
      " ('data', 0.3136),\n",
      " ('algorithm', 0.298),\n",
      " ('class', 0.296),\n",
      " ('object', 0.2789),\n",
      " ('determine', 0.2699),\n",
      " ('function', 0.2658),\n",
      " ('bias', 0.2644),\n",
      " ('task', 0.26),\n",
      " ('output', 0.2598),\n",
      " ('instances', 0.2595),\n",
      " ('machine', 0.2591),\n",
      " ('inductive', 0.2577),\n",
      " ('examples', 0.257),\n",
      " ('signal', 0.2563),\n",
      " ('input', 0.251),\n",
      " ('mapping', 0.2455),\n",
      " ('analyzes', 0.2447),\n",
      " ('generalize', 0.2434),\n",
      " ('inferred', 0.2392),\n",
      " ('maps', 0.2351),\n",
      " ('example', 0.2314),\n",
      " ('unseen', 0.2091),\n",
      " ('optimal', 0.1982),\n",
      " ('produces', 0.1561),\n",
      " ('vector', 0.1528),\n",
      " ('called', 0.1358),\n",
      " ('infers', 0.1337),\n",
      " ('scenario', 0.132),\n",
      " ('situations', 0.1231),\n",
      " ('value', 0.1168),\n",
      " ('based', 0.1165),\n",
      " ('new', 0.1136),\n",
      " ('consisting', 0.1041),\n",
      " ('set', 0.1021),\n",
      " ('pairs', 0.1003),\n",
      " ('correctly', 0.0853),\n",
      " ('desired', 0.0827),\n",
      " ('requires', 0.0723),\n",
      " ('pair', 0.057),\n",
      " ('typically', 0.0564),\n",
      " ('used', 0.0525),\n",
      " ('way', 0.0509),\n",
      " ('allow', 0.0346),\n",
      " ('reasonable', 0.0228)]\n",
      "For string:  spaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython. The library is published under the MIT license and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\n",
      "[('spacy', 0.7299),\n",
      " ('python', 0.4219),\n",
      " ('programming', 0.3304),\n",
      " ('cython', 0.3255),\n",
      " ('software', 0.3164),\n",
      " ('language', 0.2958),\n",
      " ('library', 0.2944),\n",
      " ('languages', 0.289),\n",
      " ('developers', 0.1904),\n",
      " ('processing', 0.1871),\n",
      " ('honnibal', 0.1627),\n",
      " ('montani', 0.1619),\n",
      " ('company', 0.1602),\n",
      " ('main', 0.1495),\n",
      " ('written', 0.1437),\n",
      " ('open', 0.1211),\n",
      " ('advanced', 0.1197),\n",
      " ('source', 0.119),\n",
      " ('explosion', 0.1087),\n",
      " ('published', 0.1067),\n",
      " ('license', 0.0965),\n",
      " ('ines', 0.0924),\n",
      " ('founders', 0.089),\n",
      " ('mit', 0.0646),\n",
      " ('natural', 0.0531),\n",
      " ('matthew', 0.0271)]\n",
      "For string:  wow that brightest star do you remember the pan pacific bank robbery where four people were killed and the subsequent arrest of the perp where a young man was shot and killed\n",
      "[('robbery', 0.5039),\n",
      " ('star', 0.3278),\n",
      " ('remember', 0.2995),\n",
      " ('brightest', 0.2791),\n",
      " ('bank', 0.2787),\n",
      " ('arrest', 0.2715),\n",
      " ('perp', 0.2669),\n",
      " ('wow', 0.229),\n",
      " ('killed', 0.1925),\n",
      " ('pacific', 0.1867),\n",
      " ('subsequent', 0.1722),\n",
      " ('people', 0.1534),\n",
      " ('man', 0.1389),\n",
      " ('shot', 0.1255),\n",
      " ('young', 0.1093),\n",
      " ('pan', 0.0978)]\n",
      "For string:  THE ANDNRENT AND UNACCEPTABLE TRUTH OF\n",
      "                        CUSTODIAL DEATH\n",
      "[('custodial', 0.59),\n",
      " ('death', 0.4126),\n",
      " ('truth', 0.2258),\n",
      " ('unacceptable', 0.208),\n",
      " ('andnrent', 0.1975)]\n"
     ]
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "\n",
    "docs = [\"\"\"Supervised learning is the machine learning task of learning a function that\n",
    "        maps an input to an output based on example input-output pairs. It infers a\n",
    "        function from labeled training data consisting of a set of training examples.\n",
    "        In supervised learning, each example is a pair consisting of an input object\n",
    "        (typically a vector) and a desired output value (also called the supervisory signal). \n",
    "        A supervised learning algorithm analyzes the training data and produces an inferred function, \n",
    "        which can be used for mapping new examples. An optimal scenario will allow for the \n",
    "        algorithm to correctly determine the class labels for unseen instances. This requires \n",
    "        the learning algorithm to generalize from the training data to unseen situations in a \n",
    "        'reasonable' way (see inductive bias).\"\"\", \n",
    "        \n",
    "        \"\"\"Keywords are defined as phrases that capture the main topics discussed in a document. \n",
    "        As they offer a brief yet precise summary of document content, they can be utilized for various applications. \n",
    "        In an information retrieval environment, they serve as an indication of document relevance for users, as the list \n",
    "        of keywords can quickly help to determine whether a given document is relevant to their interest. \n",
    "        As keywords reflect a document's main topics, they can be utilized to classify documents into groups \n",
    "        by measuring the overlap between the keywords assigned to them. Keywords are also used proactively \n",
    "        in information retrieval.\"\"\"]\n",
    "\n",
    "text = \"\"\"spaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython. The library is published under the MIT license and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\"\"\"\n",
    "textFromAudio = \"wow that brightest star do you remember the pan pacific bank robbery where four people were killed and the subsequent arrest of the perp where a young man was shot and killed\"\n",
    "textFromImages = \"\"\"THE ANDNRENT AND UNACCEPTABLE TRUTH OF\n",
    "                        CUSTODIAL DEATH\"\"\"\n",
    "kw_model = KeyBERT()\n",
    "def TestKeyBERT(text):\n",
    "        keys = kw_model.extract_keywords(\n",
    "                docs=text, \n",
    "                keyphrase_ngram_range=(1,1),\n",
    "                top_n= int( 0.45*len(text) )\n",
    "                )\n",
    "        print(\"For string: \",text)\n",
    "        pprint(keys)\n",
    "\n",
    "TestKeyBERT(docs[0])\n",
    "TestKeyBERT(text)\n",
    "TestKeyBERT(textFromAudio)\n",
    "TestKeyBERT(textFromImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<hr>\n",
    "\n",
    "### ARCHIVE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pytextrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"\"\"India recorded its lowest daily Covid-19 cases in over four months on Tuesday as it\n",
    "registered 30,093 fresh cases of the coronavirus disease, the Union ministry of health and\n",
    "family welfare data showed. The last time India's Covid-19 tally was below 30,000-mark was on \n",
    "March 16 when the country saw 28,903 fresh cases.\n",
    "\n",
    "The country also saw 374 deaths due to Covid-19 in the last 24 hours, taking the death toll to 414,482. This is also the lowest death count India has seen after over three months. India witnessed deaths below 400 on March 30 when 354 fatalities were recorded.\n",
    "\n",
    "Active cases of Covid-19 in the last 24 hours dipped sharply by 15,535, bringing the current infections in the country down to 406,130, the health ministry data showed. These account for 1.35% of the total infections reported in the country.\n",
    "\n",
    "At least 45,254 people recovered from the infectious disease in the last 24 hours, taking India's recovery rate to 97.32%.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_nlp = spacy.load(\"en_core_web_sm\")\n",
    "en_nlp.add_pipe(\"textrank\")\n",
    "doc = en_nlp(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.001462936401367\n"
     ]
    }
   ],
   "source": [
    "tr = doc._.textrank\n",
    "print(tr.elapsed_time);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "family welfare data 0.12600090030695432 1\n",
      "Active cases 0.10762708856818633 1\n",
      "Covid-19 0.0972910880017003 2\n",
      "its lowest daily Covid-19 cases 0.08493733074461425 1\n",
      "deaths 0.08105682814454315 1\n",
      "the health ministry data 0.07832397465246121 1\n",
      "India 0.07622677252903803 8\n",
      "28,903 fresh cases 0.07129934511205784 1\n",
      "30,093 fresh cases 0.07129934511205784 1\n",
      "health 0.07040385930179857 1\n",
      "Indias Covid-19 tally 0.06832929773944697 1\n",
      "March 0.06820137241457065 2\n",
      "Tuesday 0.06730934841577292 2\n",
      "the Union ministry 0.05804340764065743 1\n",
      "daily 0.05801486530369755 1\n",
      "the health ministry 0.05736999157497043 1\n",
      "Indias recovery rate 0.05719488369024152 1\n",
      "the coronavirus disease 0.05620344960951462 1\n",
      "the lowest death count 0.055052440762211316 1\n",
      "The country 0.052203381342001136 1\n",
      "the country 0.052203381342001136 3\n",
      "the Union ministry of health 0.051315344525987495 1\n",
      "the current infections 0.05102621920759585 1\n",
      "the total infections 0.050044489310882095 1\n",
      "the death toll 0.04958030523542612 1\n",
      "the infectious disease 0.04872959082364312 1\n",
      "the last 24 hours 0.04444644936605378 6\n",
      "374 deaths 0.03743854523912738 1\n",
      "1.35% 0.03631222553448415 2\n",
      "97.32% 0.03631222553448415 2\n",
      "three months 0.03499235800709229 1\n",
      "March 16 0.03150086457812342 1\n",
      "March 30 0.03150086457812342 1\n",
      "over four months 0.025410903713624283 2\n",
      "over three months 0.025410903713624283 1\n",
      "354 fatalities 0.024747622479328494 1\n",
      "At least 45,254 people 0.018251076082325113 1\n",
      "30,000-mark 0.017958869221694186 2\n",
      "These account 0.01537302848030652 1\n",
      "At least 45,254 0.011163653115937398 1\n",
      "15,535 0.0 1\n",
      "28,903 0.0 1\n",
      "30,093 0.0 1\n",
      "354 0.0 1\n",
      "374 0.0 1\n",
      "400 0.0 1\n",
      "406,130 0.0 1\n",
      "414,482 0.0 1\n",
      "This 0.0 1\n",
      "it 0.0 1\n"
     ]
    }
   ],
   "source": [
    "for combination in doc._.phrases:\n",
    "    print(combination.text, combination.rank, combination.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase(text='family welfare data', chunks=[family welfare data], count=1, rank=0.12600090030695432)\n",
      "Phrase(text='Active cases', chunks=[Active cases], count=1, rank=0.10762708856818633)\n",
      "Phrase(text='Covid-19', chunks=[Covid-19, Covid-19], count=2, rank=0.0972910880017003)\n",
      "Phrase(text='its lowest daily Covid-19 cases', chunks=[its lowest daily Covid-19 cases], count=1, rank=0.08493733074461425)\n",
      "Phrase(text='deaths', chunks=[deaths], count=1, rank=0.08105682814454315)\n"
     ]
    }
   ],
   "source": [
    "en_nlp = spacy.load(\"en_core_web_sm\")\n",
    "en_nlp.add_pipe(\"textrank\", config={ \"stopwords\": { \"word\": [\"NOUN\"] } })\n",
    "doc = en_nlp(document)\n",
    "for phrase in doc._.phrases[:5]:\n",
    "    print(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"India recorded its lowest daily Covid-19 cases in over four months on Tuesday as it\\nregistered 30,093 fresh cases of the coronavirus disease, the Union ministry of health and\\nfamily welfare data showed. The last time India's Covid-19 tally was below 30,000-mark was on \\nMarch 16 when the country saw 28,903 fresh cases.\\n\\nThe country also saw 374 deaths due to Covid-19 in the last 24 hours, taking the death toll to 414,482. This is also the lowest death count India has seen after over three months. India witnessed deaths below 400 on March 30 when 354 fatalities were recorded.\\n\\nActive cases of Covid-19 in the last 24 hours dipped sharply by 15,535, bringing the current infections in the country down to 406,130, the health ministry data showed. These account for 1.35% of the total infections reported in the country.\\n\\nAt least 45,254 people recovered from the infectious disease in the last 24 hours, taking India's recovery rate to 97.32%.\""
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India recorded its lowest daily Covid-19 cases in over four months on Tuesday as it\n",
      "registered 30,093 fresh cases of the coronavirus disease, the Union ministry of health and\n",
      "family welfare data showed.\n",
      "Active cases of Covid-19 in the last 24 hours dipped sharply by 15,535, bringing the current infections in the country down to 406,130, the health ministry data showed.\n"
     ]
    }
   ],
   "source": [
    "tr = doc._.textrank\n",
    "for sent in tr.summary(limit_phrases=10, limit_sentences=2):\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India recorded its lowest daily Covid-19 cases in over four months on Tuesday as it\n",
      "Active cases of Covid-19 in the last 24 hours dipped sharply by 15,535, bringing the current infections in the country down to 406,130, the health ministry data showed.\n"
     ]
    }
   ],
   "source": [
    "from summa import summarizer\n",
    "from summa import keywords\n",
    "print(summarizer.summarize(document))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "india\n",
      "deaths\n",
      "death\n",
      "infections\n",
      "ministry\n",
      "data\n",
      "disease\n",
      "covid\n",
      "fresh\n"
     ]
    }
   ],
   "source": [
    "print(keywords.keywords(document))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "daca86dfe90386ebecafa86302dd102978461e1263ffd5af8c9f541b523ba9f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
