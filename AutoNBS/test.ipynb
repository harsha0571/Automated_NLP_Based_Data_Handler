{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from console_explorer import * \n",
    "\n",
    "\n",
    "\n",
    "# Creating the two required variables\n",
    "text = \"\"  # The file's text\n",
    "user_input = \"\"  # The user input (just initialized, here)\n",
    "\n",
    "# Looping until the user types 'EXIT'\n",
    "while user_input != \"EXIT\":\n",
    "    # Asking him a line\n",
    "    user_input = input(\"\")\n",
    "    # If the line is not 'EXIT' (which would mean we are done writing the text), we add the\n",
    "    # inputted line to the text\n",
    "    if not user_input == \"EXIT\": text += user_input + \"\\n\"\n",
    "\n",
    "# We ask the user to choose the file destination.\n",
    "# Also, we only want it to be a plain text (.txt) file or Markdown file (.md)\n",
    "file_to_save_in = browse_for_file(extensions_list=(\"txt\", \"md\"))\n",
    "\n",
    "# If the user cancelled the save, we simply pass\n",
    "if file_to_save_in is None:\n",
    "    pass\n",
    "# Otherwise, we open the file he selected, and we put the text inside.\n",
    "else:\n",
    "    with open(file_to_save_in, \"w\") as file:\n",
    "        file.write(text[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tkinter import Tk     # from tkinter import Tk for Python 3.x\n",
    "from tkinter.filedialog import askopenfilename\n",
    "\n",
    "Tk().withdraw() # we don't want a full GUI, so keep the root window from appearing\n",
    "filename = askopenfilename() # show an \"Open\" dialog box and return the path to the selected file\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import Tk     \n",
    "import tkinter.filedialog as fd\n",
    "\n",
    "Tk().withdraw() # we don't want a full GUI, so keep the root window from appearing\n",
    "files = fd.askopenfilenames(title='Choose files to upload') # show an \"Open\" dialog box and return the path to the selected file\n",
    "list_files = list(files)\n",
    "print(list_files)\n",
    "Tk().destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  9.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    sleep(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  9.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "from time import sleep\n",
    "\n",
    "for i in trange(100):\n",
    "    sleep(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 10/10 [00:04<00:00,  2.44it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, 10), desc =\"Progress: \"):\n",
    "    sleep(.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsit = [\"abc\" for i in range(100000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsit.append(\"ce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "l  = [\"ab\",\"ce\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ce']\n",
      "3.6123690605163574\n"
     ]
    }
   ],
   "source": [
    "# Python program to get the intersection  \n",
    "# of two lists in most simple way  \n",
    "import time\n",
    "def intersection_list(list1, list2):  \n",
    "    list3 = [value for value in list1 if value in list2]  \n",
    "    return list3  \n",
    "\n",
    "# Driver Code  \n",
    "start = time.time()\n",
    "print(intersection_list(lsit, l))  \n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ce']\n",
      "0.5226030349731445\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "res = list(set(lsit).intersection(set(l)))\n",
    "end = time.time()\n",
    "print(res)\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "df = h5py.File('./index/doc_info.hdf5', 'r')\n",
    "dataset = df['my_dataset']\n",
    "data = dataset[:]\n",
    "for i,val in enumerate(data):\n",
    "    print(i,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"D:/code/aiml/Final Year Project/Automated_NLP_Based_Data_Handler/datasets/text/3.txt\",'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 682: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9130c628a977>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:/code/aiml/Final Year Project/Automated_NLP_Based_Data_Handler/datasets/text/8.txt'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mcontents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Harsha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 682: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "with open('D:/code/aiml/Final Year Project/Automated_NLP_Based_Data_Handler/datasets/text/8.txt') as f:\n",
    "    contents = f.read()\n",
    "    print(type(contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "def extract_doc(filename):\n",
    "    doc = docx.Document(filename)\n",
    "    text = []\n",
    "    for para in doc.paragraphs:\n",
    "        text.append(para.text)\n",
    "    textFromDoc = '\\n'.join(text)\n",
    "    # tempTuple = os.path.splitext(filename)\n",
    "    # filename = tempTuple[0]\n",
    "    # with open(f\"{filename}.txt\", 'w', encoding='utf-8') as f:\n",
    "    #     f.write(text1)\n",
    "    # print(\"Doc data converted to text file\")\n",
    "    return textFromDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "txt = extract_doc('D:/code/aiml/Technical Seminar/Seperator Sheets.docx')\n",
    "\n",
    "print(type(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import whisper\n",
    "def extract_aud(filename):\n",
    "    model = whisper.load_model(\"small.pt\")\n",
    "    result = model.transcribe(filename)\n",
    "    # tempTuple = os.path.splitext(filename)\n",
    "    # filename = tempTuple[0]\n",
    "    # with open(f\"{filename}.txt\", 'w', encoding='utf-8') as f:\n",
    "    #     f.write(result[\"text\"])\n",
    "    # print(\"Audio data converted to text file\")\n",
    "    return result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      " Central Bank Digital Currency is the electronic version of the paper currencies. It is acceptable as a medium of payment legal tender and a safe store of health. With a cart unlike virtual currencies, CVDC is a centralized central bank issue and have the same value as that of the physical currency. Many countries are soon interested in what's given because of their bestie requirements. It is in these three columns, least based pilot state in the interest-based countries. The design of CVDC depends on the scope of transaction, model of issuance, positive interest or negative interest, induction, mode of authentication and degree of anonymity. Its architecture current implementation as implications will be discussed in this presentation.\n"
     ]
    }
   ],
   "source": [
    "aud_txt = extract_aud(\"D:/code/aiml/Final Year Project/Automated_NLP_Based_Data_Handler/datasets/a.wav\")\n",
    "print(type(aud_txt))\n",
    "print(aud_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "# import filecmp\n",
    "import easyocr\n",
    "import whisper\n",
    "import pdfplumber\n",
    "import warnings\n",
    "import docx\n",
    "from brisque import BRISQUE\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def extract_img(filename):\n",
    "    try:\n",
    "        img = Image.open(filename)\n",
    "        print(\"test\",img)\n",
    "        numpydata = asarray(img)\n",
    "        obj = BRISQUE(url=False)\n",
    "        score = obj.score(numpydata)\n",
    "        if score <= 90:\n",
    "            reader = easyocr.Reader(['en'])\n",
    "            results = reader.readtext(filename, detail=0)\n",
    "            tempTuple = os.path.splitext(filename)\n",
    "            filename = tempTuple[0]\n",
    "            \n",
    "            text  = \"\\n\".join(results)\n",
    "            return text\n",
    "            \n",
    "        else:\n",
    "            print(\n",
    "                \"The image file has lot of noise and is unsuitable for extraction of text\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"The image has lots of noise,hence unsuitable for extraction of text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pytesseract import pytesseract\n",
    "\n",
    "def get_text_image_tesseract(filename):\n",
    "    pathToTesseract= r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "    pytesseract.tesseract_cmd= pathToTesseract\n",
    "    text = pytesseract.image_to_string(filename)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=331x152 at 0x21E8A2D4C40>\n",
      "<class 'str'>\n",
      "HAWAHI\n"
     ]
    }
   ],
   "source": [
    "# img_txt = get_text_image_tesseract(\"D:/code/aiml/Final Year Project/Automated_NLP_Based_Data_Handler/datasets/images/66.jpg\")\n",
    "img_txt = extract_img(\"D:/code/aiml/Final Year Project/Automated_NLP_Based_Data_Handler/datasets/images/66.jpg\")\n",
    "# img_txt = extract_img('tester.png')\n",
    "print(type(img_txt))\n",
    "print(img_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_pdf(filename):\n",
    "    try:\n",
    "        with pdfplumber.open(filename) as doc:\n",
    "            text = \"\"\n",
    "            for page in doc.pages:\n",
    "                text += page.extract_text()\n",
    "        return text\n",
    "    except:\n",
    "        print(\"failed to extract text from this pdf hence skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "kw_model = KeyBERT()\n",
    "\n",
    "test = \"\"\"Supervised learning is the machine learning task of learning a function that\n",
    "        maps an input to an output based on example input-output pairs. It infers a\n",
    "        function from labeled training data consisting of a set of training examples.\n",
    "        In supervised learning, each example is a pair consisting of an input object\n",
    "        (typically a vector) and a desired output value (also called the supervisory signal). \n",
    "        A supervised learning algorithm analyzes the training data and produces an inferred function, \n",
    "        which can be used for mapping new examples. An optimal scenario will allow for the \n",
    "        algorithm to correctly determine the class labels for unseen instances. This requires \n",
    "        the learning algorithm to generalize from the training data to unseen situations in a \n",
    "        'reasonable' way (see inductive bias).\"\"\"\n",
    "\n",
    "def get_keywords_KeyBert(text):\n",
    "        keys = kw_model.extract_keywords(\n",
    "                docs=text, \n",
    "                keyphrase_ngram_range=(1,1),\n",
    "                top_n= int( 0.41*len(text) )\n",
    "                )\n",
    "        return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = get_keywords_KeyBert(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('supervised', 0.6676),\n",
       " ('labeled', 0.4896),\n",
       " ('learning', 0.4813),\n",
       " ('training', 0.4134),\n",
       " ('labels', 0.3947),\n",
       " ('supervisory', 0.3297),\n",
       " ('data', 0.3136),\n",
       " ('algorithm', 0.298),\n",
       " ('class', 0.296),\n",
       " ('object', 0.2789),\n",
       " ('determine', 0.2699),\n",
       " ('function', 0.2658),\n",
       " ('bias', 0.2644),\n",
       " ('task', 0.26),\n",
       " ('output', 0.2598),\n",
       " ('instances', 0.2595),\n",
       " ('machine', 0.2591),\n",
       " ('inductive', 0.2577),\n",
       " ('examples', 0.257),\n",
       " ('signal', 0.2563),\n",
       " ('input', 0.251),\n",
       " ('mapping', 0.2455),\n",
       " ('analyzes', 0.2447),\n",
       " ('generalize', 0.2434),\n",
       " ('inferred', 0.2392),\n",
       " ('maps', 0.2351),\n",
       " ('example', 0.2314),\n",
       " ('unseen', 0.2091),\n",
       " ('optimal', 0.1982),\n",
       " ('produces', 0.1561),\n",
       " ('vector', 0.1528),\n",
       " ('called', 0.1358),\n",
       " ('infers', 0.1337),\n",
       " ('scenario', 0.132),\n",
       " ('situations', 0.1231),\n",
       " ('value', 0.1168),\n",
       " ('based', 0.1165),\n",
       " ('new', 0.1136),\n",
       " ('consisting', 0.1041),\n",
       " ('set', 0.1021),\n",
       " ('pairs', 0.1003),\n",
       " ('correctly', 0.0853),\n",
       " ('desired', 0.0827),\n",
       " ('requires', 0.0723),\n",
       " ('pair', 0.057),\n",
       " ('typically', 0.0564),\n",
       " ('used', 0.0525),\n",
       " ('way', 0.0509),\n",
       " ('allow', 0.0346),\n",
       " ('reasonable', 0.0228)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def generate_json_keywords(keys):\n",
    "    array =[]\n",
    "    dict = {}\n",
    "    dict[\"doc_loc\"] = \"dsklfjkdalsjfaklds\"\n",
    "    keywords = []\n",
    "    for key in keys:\n",
    "        keyDict = {}\n",
    "        keyDict[\"keyword\"] = key[0]\n",
    "        keyDict[\"score\"] = key[1]\n",
    "        keywords.append(keyDict)\n",
    "\n",
    "    dict[\"keywords_array\"] = keywords\n",
    "    array.append(dict)\n",
    "    return json.dumps(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"doc_loc\": \"dsklfjkdalsjfaklds\", \"keywords_array\": [{\"keyword\": \"supervised\", \"score\": 0.6676}, {\"keyword\": \"labeled\", \"score\": 0.4896}, {\"keyword\": \"learning\", \"score\": 0.4813}, {\"keyword\": \"training\", \"score\": 0.4134}, {\"keyword\": \"labels\", \"score\": 0.3947}, {\"keyword\": \"supervisory\", \"score\": 0.3297}, {\"keyword\": \"data\", \"score\": 0.3136}, {\"keyword\": \"algorithm\", \"score\": 0.298}, {\"keyword\": \"class\", \"score\": 0.296}, {\"keyword\": \"object\", \"score\": 0.2789}, {\"keyword\": \"determine\", \"score\": 0.2699}, {\"keyword\": \"function\", \"score\": 0.2658}, {\"keyword\": \"bias\", \"score\": 0.2644}, {\"keyword\": \"task\", \"score\": 0.26}, {\"keyword\": \"output\", \"score\": 0.2598}, {\"keyword\": \"instances\", \"score\": 0.2595}, {\"keyword\": \"machine\", \"score\": 0.2591}, {\"keyword\": \"inductive\", \"score\": 0.2577}, {\"keyword\": \"examples\", \"score\": 0.257}, {\"keyword\": \"signal\", \"score\": 0.2563}, {\"keyword\": \"input\", \"score\": 0.251}, {\"keyword\": \"mapping\", \"score\": 0.2455}, {\"keyword\": \"analyzes\", \"score\": 0.2447}, {\"keyword\": \"generalize\", \"score\": 0.2434}, {\"keyword\": \"inferred\", \"score\": 0.2392}, {\"keyword\": \"maps\", \"score\": 0.2351}, {\"keyword\": \"example\", \"score\": 0.2314}, {\"keyword\": \"unseen\", \"score\": 0.2091}, {\"keyword\": \"optimal\", \"score\": 0.1982}, {\"keyword\": \"produces\", \"score\": 0.1561}, {\"keyword\": \"vector\", \"score\": 0.1528}, {\"keyword\": \"called\", \"score\": 0.1358}, {\"keyword\": \"infers\", \"score\": 0.1337}, {\"keyword\": \"scenario\", \"score\": 0.132}, {\"keyword\": \"situations\", \"score\": 0.1231}, {\"keyword\": \"value\", \"score\": 0.1168}, {\"keyword\": \"based\", \"score\": 0.1165}, {\"keyword\": \"new\", \"score\": 0.1136}, {\"keyword\": \"consisting\", \"score\": 0.1041}, {\"keyword\": \"set\", \"score\": 0.1021}, {\"keyword\": \"pairs\", \"score\": 0.1003}, {\"keyword\": \"correctly\", \"score\": 0.0853}, {\"keyword\": \"desired\", \"score\": 0.0827}, {\"keyword\": \"requires\", \"score\": 0.0723}, {\"keyword\": \"pair\", \"score\": 0.057}, {\"keyword\": \"typically\", \"score\": 0.0564}, {\"keyword\": \"used\", \"score\": 0.0525}, {\"keyword\": \"way\", \"score\": 0.0509}, {\"keyword\": \"allow\", \"score\": 0.0346}, {\"keyword\": \"reasonable\", \"score\": 0.0228}]}]'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_json_keywords(keys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
